{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡BIENVENIDO, GUARDIÁN DEL ECOSISTEMA!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .p-Widget.jp-OutputPrompt.jp-OutputArea-prompt:empty {\n",
       "              padding: 0;\n",
       "              border: 0;\n",
       "        }\n",
       "    </style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pftoolbox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pftoolbox.tables import query2df\n",
    "from pftoolbox.fraud import simulation\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import click\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "%run db_access.py\n",
    "%run credenciales.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aclaraciones: \n",
    "- Pensado para cortes más restrictivos esto, no para flexibilizaciones. Se necesita suponer por ejemplo que el incoming de nuevos grupos que hoy se rechaza es 100% por ejemplo\n",
    "\n",
    "- Considero solo flow.type: MI . En redshift no hace falta esta aclaración\n",
    "- PAY_PM_TYPE_ID  in ('credit_card','debit_card')\n",
    "- Considero solo config_id: 'OFF','GTW','REC'. En redshift trae esto, sería no traer STD ni 'MIS'\n",
    "- Considero solo flujo aprobado (A y D) \n",
    "- Tomo de base en la join a la tabla de Tera\n",
    "- Redshift nose porque, en los días limites hay pagos que no trae, por eso le pido que en redshift, traiga un dia de mas y un día de menos, por lo que siempre, redshift debería tener algunos pagos de mas\n",
    "- Redshift suele actualizar los pagos un poco más tarde, por lo que hay pagos del día de ayer que puede que no esten en Redshift\n",
    "CON ESTAS REGLAS, REDSHIFT SIEMPRE DEBERÍA TRAER 2 DIAS DE PAGOS DE MÁS. Nose porque, a veces aleatoreamente teradata con esta logica trae menos pagos... igual es menos de 0,5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seller=click.prompt(\"Ingresar nombre del Seller\")\n",
    "# desde = click.prompt(\"Desde\", default=(dt.datetime.now()+relativedelta(months=-2)).strftime(\"%Y-%m-%d\"))\n",
    "# hasta=click.prompt(\"Hasta\", default=(dt.datetime.now()).strftime(\"%Y-%m-%d\"))\n",
    "# Reintentos=click.prompt(\"Se trabaja con o sin reintentos?\", default='Sin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino variables\n",
    "desde='2021-07-15'  #'2020-10-01'\n",
    "hasta='2021-08-18'\n",
    "Seller='419721672' #pichau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nose porque este campo: spr.creation_date trae menos campos y tengo que extenderle los limites\n",
    "desde2=((pd.to_datetime(desde))+dt.timedelta(days=-1)).strftime(\"%Y-%m-%d\")\n",
    "hasta2=((pd.to_datetime(hasta))+dt.timedelta(days=1)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reintentos='Con'  #'Sin'/'Con'\n",
    "Regla_En='Redshift' #Redshift/Teradata\n",
    "# Periodo='dia'    #/dias/semana/mes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de querer trabajar sobre un flujo puntual, llamar \"regla\" al flujo como variable, no como filtro! y se trabajará sobre cuando la regla es==1. Si se define en Redshift, aclararlo arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglaTera=''\n",
    "reglaRedshift=\"\"\"case when datediff(day, dev.creation_Date, so.creation_date) < 7then 0 else 1 end regla,\"\"\" #and so.has_approved_payment_tc='N' \n",
    "\n",
    "# --Reglas REDSHIFT\n",
    "# --case when datediff(day, dev.creation_Date, so.creation_date) < 7 and datediff(day, cus_sen.site_since, so.creation_date) > 7 and pp.mp_prod_id in ('BC32A1FTRPP001U8NHFG','BF6T4TL5G6HG01KPO2LG','BD72KDPQIJ2G01BAK93G','BC32BHVTRPP001U8NHL0','BJEO9TFBF6RG01IIIOU0','BC32CANTRPP001U8NHO0','BC32BQJU643001OI397G','BJDGPHVBF6RG01IIIOSG','BF3L8CCEVKKG01NFMI70','BEL8E9E0CAH001G99FI0','BF3L7UNP2P4001H0L200','BT7OFH09QS3001K5A0H0','BT7OEN7EOO6G01NJK3Q0','BSOO1O89QS3001K5A0GG','BC32CCRU643001OI39AG','BCT80R50FCR001F95260','BEVP8TU8QCDG01NJH370','BT7OE9FEOO6G01NJK3PG','BF3L7V7P2P4001H0L21G','BT7OF5FEOO6G01NJK3QG','BC32A7VTRPP001U8NHK0','BF3L8C7P2P4001H0L220','BC329V3U643001OI3910','BFRFF6JDNCEG02A7IS1G','BJDGOQNBF6RG01IIIORG','BSOO28NEOO6G01NJK3O0','BJEO9NVBF6RG01IIIOTG','BF3L7UVP2P4001H0L210','BF3L7V4EVKKG01NFMI6G','BC32A7RU643001OI3940','BC32A4RU643001OI3930','BC32A7VTRPP001U8NHJ0','BC32A57TRPP001U8NHHG','BC32C7VTRPP001U8NHNG','BRP4K1BTEN2001J1IEH0','BC32CPFTRPP001U8NHRG','BF3JOAKEVKKG01NFMI1G','BF3L7V4EVKKG01NFMI60') then 0 else 1 end regla,\n",
    "\n",
    "# --Reglas SOR\n",
    "# --to_char(case when ( sor.creation_date <= dev.frd_device_ml_creation_date + interval '7' day) then 1 else 0 END) regla,\n",
    "# --prod2.MP_PROD_USER_TYPE='guest'and sor.creation_date <= dev.frd_device_ml_creation_date + interval '15' day and FRD_HAS_APPROVED_PAYMENT_TC='N' and  op_dol_amount >50\n",
    "# --to_char(case when (prod2.MP_PROD_USER_TYPE='guest'and sor.creation_date <= dev.frd_device_ml_creation_date + interval '15' day and FRD_HAS_APPROVED_PAYMENT_TC='N' and  op_dol_amount >50) then 1 else 0 END) regla,\n",
    "# --to_char(case when((cast(sor.creation_date as date format 'yyyy-mm-dd') - cast(dev.FRD_DEVICE_ML_CREATION_DATE as date format 'yyyy-mm-dd'))<7) then 1 else 0 end) regla,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:\t1 query(ies)\n",
      "\t0 create(s)\n",
      "\t1 select(s)\n",
      "\t0 drop(s) excluded\n",
      "\t0 other(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing queries', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo:\t452.31 segs \n",
      "\n",
      "Output:\tdf con 11135 registros\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SC_CUST_ID</th>\n",
       "      <th>PAY_PAYMENT_ID</th>\n",
       "      <th>PAY_TRY_LAST</th>\n",
       "      <th>FLAG_NOTIF_CBK</th>\n",
       "      <th>site_id</th>\n",
       "      <th>PCC_STATUS</th>\n",
       "      <th>STC_PROFILE_ID</th>\n",
       "      <th>TeraRisk</th>\n",
       "      <th>creationdate</th>\n",
       "      <th>cbk transac Hispanos</th>\n",
       "      <th>cbk trasnc MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.700348e+11</td>\n",
       "      <td>1.600191e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB</td>\n",
       "      <td>A</td>\n",
       "      <td>MIDHIGH</td>\n",
       "      <td>18</td>\n",
       "      <td>2021-07-23-02</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.697091e+11</td>\n",
       "      <td>1.591949e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB</td>\n",
       "      <td>A</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2021-07-18-04</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.699068e+11</td>\n",
       "      <td>1.596845e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB</td>\n",
       "      <td>A</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2021-07-21-03</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.700938e+11</td>\n",
       "      <td>1.601723e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB</td>\n",
       "      <td>A</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-07-24-12</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.694072e+11</td>\n",
       "      <td>1.590028e+10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MLB</td>\n",
       "      <td>A</td>\n",
       "      <td>LOW</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2021-07-17-11</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Me traigo try last y la notificacion de cbks\n",
    "\n",
    "query01= \"\"\"\n",
    "Select\n",
    "\"\"\"\n",
    "query010=\"\"\"\n",
    "sor.sc_cust_id,\n",
    "sor.pay_payment_id,\n",
    "sor.pay_try_last,\n",
    "sor.flag_notif_cbk,\n",
    "sor.site_id,\n",
    "sor.pcc_status,\n",
    "sor.stc_profile_id,\n",
    "to_char(sor.risk) TeraRisk,\n",
    "to_char(sor.creation_date ,'yyyy-mm-dd-hh') creationdate,\n",
    "(case when (cbk.FRD_CST_DISPUTE_STATUS='WON' or (cbk.FRD_CST_DISABLE_BUY_MP=0 and not cbk.FRD_CST_NEGOT_STAT_BUY_ID = 'TKO')) then 1 ELSE 0 END ) as \"cbk transac Hispanos\",\n",
    "cbk.FRD_CST_FRAUD_STAT_BUY_ID as \"cbk trasnc MLB\"\n",
    "from SCORING.scoring_origin_report_all sor\n",
    "left join WHOWNER.BT_FRAUD_CBK_CASES cbk on cbk.payment_id=sor.pay_payment_id --MAS DETALLE GESITÓN CBK\n",
    "left join WHOWNER.BT_MP_PRODUCTS prod2 on prod2.mp_prod_id=sor.mp_prod_id --saber si el pago fue guest\n",
    "left join WHOWNER.LK_FRAUD_DEVICE dev on dev.pay_payment_id=sor.pay_payment_id --info del device\n",
    "\n",
    "where 1=1\n",
    "\n",
    "and sor.pcc_status in ('A','D','I') \n",
    "and PAY_PM_TYPE_ID in ('credit_card','debit_card')\n",
    "and sor.config_id in ('OFF','REC')--,'GTW','REC','MIS') \n",
    "and sor.flow_type='MI'\n",
    "\n",
    "and sor.creation_date>= date'\"\"\"\n",
    "query03=\"'and sor.creation_date<= date'\"\n",
    "query04= \"' and sor.cus_cust_id_sel in (\"\n",
    "query05=\") --sample 30000\"\n",
    "query06=query01+reglaTera+query010+desde+query03+hasta+query04+Seller+query05\n",
    "\n",
    "# df2=query2df.redshift(query2,credenciales,RS_access,exclude_drop=True)\n",
    "dfT=query2df.teradata(query06,credenciales,TERA_access,exclude_drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:\t1 query(ies)\n",
      "\t0 create(s)\n",
      "\t1 select(s)\n",
      "\t0 drop(s) excluded\n",
      "\t0 other(s)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f4b5d141a24d0b9fa401a4b1e639f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing queries', max=1.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalError",
     "evalue": "(psycopg2.errors.InternalError_) Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\nDETAIL:  \n  -----------------------------------------------\n  error:  Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  code:      1078\n  context:   Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  query:     0\n  location:  wlm_query_action.cpp:156\n  process:   wlm [pid=45732]\n  -----------------------------------------------\n\n\n[SQL: Select case when datediff(day, dev.creation_Date, so.creation_date) < 7then 0 else 1 end regla, so.pay_payment_id, so.scoring_id, to_char(so.creation_date,'yyyy-mm-dd') as dia, st.tree_id, so.last_node, node_id, so.risk, so.op_dol_amount from  fraud.public.scoring_origin_mi so left join scoring.scoring_provider_result spr on so.scoring_id=spr.scoring_id and so.provider_id = spr.scoring_provider left join scoring.scoring_tree_version st on st.scoring_id = spr.external_id and so.site_id = st.site_id left join scoring.hypothesis_tree_node htn on htn.tree_id = st.tree_id and htn.tree_version_id = st.tree_version_id and htn.site_id = st.site_id and htn.node_position = trunc(so.last_node/2) left join fraud.scoring.bt_mp_pay_payments pp on  pp.pay_payment_id = so.pay_payment_id left join scoring_mi.customers cus_sen on (so.scoring_id = cus_sen.scoring_id and cus_sen.cust_id = so.sender_id) left join scoring_mi.device_ml dev on (so.scoring_id = dev.scoring_id)     where 1=1  and so.pcc_status in ('A','D','I') and so.receiver_id in (419721672) and so.creation_date>=date '2021-07-14' and spr.creation_date>=date '2021-07-14' and st.op_timestamp>=date '2021-07-14' and so.creation_date<=date '2021-08-19' and spr.creation_date<=date '2021-08-19' and st.op_timestamp<=date '2021-08-19']\n(Background on this error at: http://sqlalche.me/e/13/2j85)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError_\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError_\u001b[0m: Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\nDETAIL:  \n  -----------------------------------------------\n  error:  Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  code:      1078\n  context:   Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  query:     0\n  location:  wlm_query_action.cpp:156\n  process:   wlm [pid=45732]\n  -----------------------------------------------\n\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5ad9b2ae510b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery01b\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mreglaRedshift\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery10\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mSeller\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery11\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdesde2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery12\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdesde2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery13\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdesde2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery15\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhasta2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery16\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhasta2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery17\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mhasta2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mquery14\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mdfUR\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery2df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mredshift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcredenciales\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRS_access\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexclude_drop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;31m# dfIn=query2df.teradata(query,credenciales,TERA_access,exclude_drop=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pftoolbox\\tables\\query2df.py\u001b[0m in \u001b[0;36mredshift\u001b[1;34m(query, credenciales, db_access, show_progress, show_head, id_return, exclude_drop)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m             \u001b[0mq2df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    430\u001b[0m         )\n\u001b[0;32m    431\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         return pandas_sql.read_query(\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mread_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1085\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m         \u001b[1;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1087\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m     def read_table(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2237\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_contextual_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2238\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2240\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \"\"\"\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[1;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_distill_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m         ret = self._execute_context(\n\u001b[0m\u001b[0;32m   1176\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m             self._handle_dbapi_exception(\n\u001b[0m\u001b[0;32m   1318\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   1509\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m                 util.raise_(\n\u001b[0m\u001b[0;32m   1512\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;31m# credit to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m                     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: (psycopg2.errors.InternalError_) Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\nDETAIL:  \n  -----------------------------------------------\n  error:  Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  code:      1078\n  context:   Query (19521293) cancelled by WLM abort action of Query Monitoring Rule \"others_query_execution_time\".\n  query:     0\n  location:  wlm_query_action.cpp:156\n  process:   wlm [pid=45732]\n  -----------------------------------------------\n\n\n[SQL: Select case when datediff(day, dev.creation_Date, so.creation_date) < 7then 0 else 1 end regla, so.pay_payment_id, so.scoring_id, to_char(so.creation_date,'yyyy-mm-dd') as dia, st.tree_id, so.last_node, node_id, so.risk, so.op_dol_amount from  fraud.public.scoring_origin_mi so left join scoring.scoring_provider_result spr on so.scoring_id=spr.scoring_id and so.provider_id = spr.scoring_provider left join scoring.scoring_tree_version st on st.scoring_id = spr.external_id and so.site_id = st.site_id left join scoring.hypothesis_tree_node htn on htn.tree_id = st.tree_id and htn.tree_version_id = st.tree_version_id and htn.site_id = st.site_id and htn.node_position = trunc(so.last_node/2) left join fraud.scoring.bt_mp_pay_payments pp on  pp.pay_payment_id = so.pay_payment_id left join scoring_mi.customers cus_sen on (so.scoring_id = cus_sen.scoring_id and cus_sen.cust_id = so.sender_id) left join scoring_mi.device_ml dev on (so.scoring_id = dev.scoring_id)     where 1=1  and so.pcc_status in ('A','D','I') and so.receiver_id in (419721672) and so.creation_date>=date '2021-07-14' and spr.creation_date>=date '2021-07-14' and st.op_timestamp>=date '2021-07-14' and so.creation_date<=date '2021-08-19' and spr.creation_date<=date '2021-08-19' and st.op_timestamp<=date '2021-08-19']\n(Background on this error at: http://sqlalche.me/e/13/2j85)"
     ]
    }
   ],
   "source": [
    "query01b= \"\"\"\n",
    "Select\n",
    "\"\"\"\n",
    "\n",
    "query10= \"\"\"\n",
    "so.pay_payment_id,\n",
    "so.scoring_id,\n",
    "to_char(so.creation_date,'yyyy-mm-dd') as dia,\n",
    "st.tree_id,\n",
    "so.last_node,\n",
    "node_id,\n",
    "so.risk,\n",
    "so.op_dol_amount\n",
    "from  fraud.public.scoring_origin_mi so\n",
    "left join scoring.scoring_provider_result spr on so.scoring_id=spr.scoring_id and so.provider_id = spr.scoring_provider\n",
    "left join scoring.scoring_tree_version st on st.scoring_id = spr.external_id and so.site_id = st.site_id\n",
    "left join scoring.hypothesis_tree_node htn on htn.tree_id = st.tree_id and htn.tree_version_id = st.tree_version_id and htn.site_id = st.site_id and htn.node_position = trunc(so.last_node/2)\n",
    "left join fraud.scoring.bt_mp_pay_payments pp on  pp.pay_payment_id = so.pay_payment_id\n",
    "left join scoring_mi.customers cus_sen on (so.scoring_id = cus_sen.scoring_id and cus_sen.cust_id = so.sender_id)\n",
    "left join scoring_mi.device_ml dev on (so.scoring_id = dev.scoring_id)\n",
    "--left join fraud.scoring_mi.smart_id si on si.scoring_id=so.scoring_id  --qty_devices\n",
    "\n",
    "--left join fraud.scoring_mi.items_off io on so.scoring_id=io.scoring_id \n",
    "\n",
    "where 1=1\n",
    "--and so.pay_payment_id in ()\n",
    "and so.pcc_status in ('A','D','I')\n",
    "and so.receiver_id in (\"\"\"\n",
    "\n",
    "query11=\"\"\") and so.creation_date>=date '\"\"\"\n",
    "query12=\"\"\"' and spr.creation_date>=date '\"\"\"\n",
    "query13=\"\"\"' and st.op_timestamp>=date '\"\"\"\n",
    "query15=\"\"\"' and so.creation_date<=date '\"\"\"\n",
    "query16=\"\"\"' and spr.creation_date<=date '\"\"\"\n",
    "query17=\"\"\"' and st.op_timestamp<=date '\"\"\"\n",
    "query14=\"'\"\n",
    "\n",
    "query=query01b+reglaRedshift+query10+Seller+query11+desde2+query12+desde2+query13+desde2+query15+hasta2+query16+hasta2+query17+hasta2+query14\n",
    "\n",
    "dfUR=query2df.redshift(query,credenciales,RS_access,exclude_drop=True)\n",
    "# dfIn=query2df.teradata(query,credenciales,TERA_access,exclude_drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00=dfUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIn1=dfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfIn1['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']=dfIn1['FLAG_NOTIF_CBK']\n",
    "\n",
    "if (dfIn1['site_id'].max()=='MLB'):\n",
    "    IndexB = dfIn1[dfIn1['cbk trasnc MLB']=='TRANSACTIONAL'].index #Devuelve los index de los valores que estan en Lista\n",
    "    dfIn1.loc[IndexB,'FLAG_NOTIF_CBK_NO_TRANSACCIONAL'] = 0   #Reemplaza los valores de'Others' por valor en Col Ruta en los index definidos \n",
    "else:\n",
    "    IndexH = dfIn1[dfIn1['cbk transac Hispanos']==1].index #Devuelve los index de los valores que estan en Lista\n",
    "    dfIn1.loc[IndexH,'FLAG_NOTIF_CBK_NO_TRANSACCIONAL'] = 0   #Reemplaza los valores de'Others' por valor en Col Ruta en los index definidos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df00['pay_payment_id'].count()-dfT['PAY_PAYMENT_ID'].count()\n",
    "\n",
    "# print(df00['pay_payment_id'].count()) #Tera\n",
    "# print(dfT['PAY_PAYMENT_ID'].count()) #Redshift (CASI SIEMPRE DEBERIA SER MAYOR, PORQUE CONSIDERA UN DIA ANTES Y UN DIA DESPUES, ASI TERA ESTA COMPLETO)\n",
    "# print(x) #Pagos de más que hay en Tera\n",
    "# print(round((x/df00['pay_payment_id'].count())*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uno las dos bases y veo si hay muhcos campos que quedaron sin unirse. Tomo como base a la base de redshift\n",
    "dfIn1['PAY_PAYMENT_ID']=dfIn1['PAY_PAYMENT_ID'].apply(lambda x: round(x))\n",
    "\n",
    "if Regla_En=='Redshift':\n",
    "    df01=pd.merge(dfIn1,df00, left_on='PAY_PAYMENT_ID',right_on='pay_payment_id', how='right') #Tomo de base a tera\n",
    "else:\n",
    "    df01=pd.merge(dfIn1,df00, left_on='PAY_PAYMENT_ID',right_on='pay_payment_id', how='left') #Tomo de base a tera\n",
    "# df01=df01.drop(df01[df01['PAY_TRY_LAST']].isnull().index, inplace=True)\n",
    "\n",
    "# df01.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relleno los campos vacios, trabajo solo con pay_try_last\n",
    "df=df01\n",
    "df['PAY_TRY_LAST']=df['PAY_TRY_LAST'].fillna(1)\n",
    "df['FLAG_NOTIF_CBK']=df['FLAG_NOTIF_CBK'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FLAG_NOTIF_CBK'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NECESARIO CUANDO NOS INFORMAN CBKS Y NO ESTAN MARCADOS. #2 columnas: payments_id y una columna de 1, los pagos fraudes\n",
    "try:\n",
    "    path='C:/Users/mgaona/Desktop/Analisis/base python/fraude_pichau.xlsx'\n",
    "    p_fraude=pd.read_excel(path) #puede ser read_csv\n",
    "    p_fraude= pd.DataFrame(p_fraude)\n",
    "    # p_fraude['PAY_PAYMENT_ID']=p_fraude['PAY_PAYMENT_ID'].apply(lambda x: round(x))\n",
    "    # p_fraude['payment']=p_fraude['payment'].apply(lambda x: float(x))\n",
    "\n",
    "    df=pd.merge(df,p_fraude, left_on='PAY_PAYMENT_ID',right_on='PAY_PAYMENT_ID', how='left') \n",
    "\n",
    "    # df1.reset_index(inplace = True)\n",
    "    IndexR = df[df['cbks_']==1].index #Devuelve los index de los valores que estan en Lista\n",
    "    # df1['FLAG_NOTIF_CBK']='Others' #DEFINE COLUMN\n",
    "    df.loc[IndexR,'FLAG_NOTIF_CBK'] = df.loc[IndexR,'cbks_'] #Reemplaza los valores de'Others' por valor en Col Ruta en los index definidos \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['FLAG_NOTIF_CBK'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtro solo flujo de regla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Filtro solo el grupo que me interesa\n",
    "    df['regla']=df['regla'].apply(lambda x: int(x))\n",
    "    pivotR=df.pivot_table(index=['FLAG_NOTIF_CBK'],columns=['regla'],values=['op_dol_amount'],aggfunc=np.sum, margins=True) #para ver cantidad, cambiar sum por         \n",
    "    pivotR=pivotR['op_dol_amount']\n",
    "    pivotR.sort_values\n",
    "    df=df[df['regla']==1]\n",
    "#     pivotR/pivotR.sum()\n",
    "    textF='Los resultados son SOLO sobre el flujo de la regla'\n",
    "    textF='Resultados del flujo de la regla que representa '+str(round(Share_flujo_regla*100,1))+' % el flujo total. El cbk real de la regla representa '+str(round(Share_cbk_real_regla*100,1))+'% del flujo total\\n'\n",
    "\n",
    "except:\n",
    "        pivotR=0\n",
    "        print('Es todo el flujo')\n",
    "        textF='Se analizo todo el flujo del seller (a veces es sobre new device por ejemplo)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pivotR=pivotR.sort_values(by='All',ascending=False)\n",
    "    Share_flujo_regla=pivotR[1].iloc[0]/pivotR['All'].iloc[0]\n",
    "    Share_cbk_real_regla=pivotR[1].iloc[2]/pivotR['All'].iloc[2]\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (Reintentos=='Sin'):\n",
    "    df=df[df['PAY_TRY_LAST']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfM[dfM['PAY_PAYMENT_ID']==13799511661] 13759402599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simu_OK = click.prompt(\"Quiero Simular? (Revisar campos de abajo)\", default='Si')\n",
    "N_Muestra=click.prompt(\"Cantidad de pagos\", default=df['PAY_PAYMENT_ID'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'Pichau sin fato'\n",
    "setteos     = {'tree':         'PRUEBA_TUTE',\n",
    "               'tree_version': 107,\n",
    "               'site':         'MLB',\n",
    "               'flow':         'MI',\n",
    "               'team':         'prod_bsas'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim='No'\n",
    "if Simu_OK=='Si':\n",
    "    dfM=df\n",
    "    if int(N_Muestra) != (df['PAY_PAYMENT_ID'].count()):\n",
    "        dfM=df.sample(n=int(N_Muestra))\n",
    "    dfM['PAY_PAYMENT_ID2']=dfM['PAY_PAYMENT_ID']\n",
    "    dfM=dfM.drop(labels='PAY_PAYMENT_ID',axis=1)\n",
    "    results=simulation.execute(dfM,description,setteos)\n",
    "    Sim=='Si'\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Simu_OK=='Si':\n",
    "    results['risk']=results['risk']\n",
    "    #  results['risk']=results.iloc[:,-2:-1]\n",
    "    results['op_dol_amount']=results['op_dol_amount']\n",
    "    results['tree_id']=setteos['tree']\n",
    "    df=results\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Termina Simulacón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Miro de todo el flujo, en que provider/arbol terminó (se entiende entonces que es flujo OFF/GTW, MI, regular)\n",
    "if Simu_OK=='Si':\n",
    "    df['tree_id']=df['TREE_ID'].fillna('N/A')\n",
    "    df['op_dol_amount']=df['OP_DOL_AMOUNT']\n",
    "    df['node_id']=df['NODE_ID']\n",
    "    df['risk']=df['RISK']\n",
    "    #df['PAY_PAYMENT_ID'].apply(lambda x: round(x))\n",
    "else:\n",
    "    df['tree_id']=df['tree_id'].fillna('N/A')\n",
    "    \n",
    "pivot_0=df.pivot_table(index=['tree_id'],values=['op_dol_amount'],aggfunc=np.size).sort_values(by='op_dol_amount',ascending=False) #para ver cantidad, cambiar sum por         \n",
    "plt.pie(pivot_0['op_dol_amount'],labels=pivot_0.index,autopct='%.2f')\n",
    "plt.show()\n",
    "df['tree_id'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = click.prompt(\"Ingresar el arbol\", default=str(pivot_0.index[0]))\n",
    "percentil=click.prompt(\"Ingresar cantidad de grupos\", default=10)\n",
    "regla=click.prompt(\"Ingresar nombre de la regla\", default='Sin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree=input('Seleccionar el Arbol')\n",
    "# percentil=input('Seleccionar percentil')\n",
    "# regla=input('Seleccionar la regla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Miro cuales fueron los nodos de rechazo, según el arbol seleccionado\n",
    "\n",
    "# tree='ONLINE_PAYMENTS_CA_ALPHA' #Aca hay que elegir\n",
    "# percentil=10 #multiplo de 100. el % que quiero que tenga cada cuadradito\n",
    "# regla='Sin'  #'Sin'/'Nombre de la regla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto2='El '+str(int(pivot_0['op_dol_amount'][0]/pivot_0['op_dol_amount'].sum()*100))+' % del flujo es por el arbol '+str(tree)\n",
    "\n",
    "# df['node_id']=df['node_id'].fillna('Aprobado')\n",
    "pivot_1=df[(df['PCC_STATUS']=='I')&(df['tree_id']==tree)].pivot_table(index=['node_id'],values=['op_dol_amount'],aggfunc=np.sum).sort_values(by='op_dol_amount',ascending=False)   \n",
    "plt.pie(pivot_1['op_dol_amount'],labels=pivot_1.index,autopct='%.2f')\n",
    "plt.show()\n",
    "df['node_id'].unique()\n",
    "texto0='El '+str(int(pivot_1['op_dol_amount'][0]/pivot_1['op_dol_amount'].sum()*100))+' % del rechazo es por el nodo '+str(pivot_1.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acomodo los formatos, y me quedo solo con: el arbol seleccionado arriba, y los pagos con risk<1\n",
    "# df['op_dol_amount']=df['op_dol_amount'].fillna(0)\n",
    "df['op_dol_amount']=df['op_dol_amount'].apply(lambda x: float(x))\n",
    "df=df[df['risk']!=''] #Si no trae RISK, es porque en SrongRules tuvo profile MIDINH O HIGH\n",
    "df['risk']=df['risk'].fillna(0)\n",
    "# df['risk']=df['risk'].replace(np.nan,df['TeraRisk']) #reemplasa NaN/None (sin valor) por la media de una columna\n",
    "df['risk']=df['risk'].apply(lambda x: float(x))\n",
    "df=df[(df['risk']<=1)&(df['tree_id']==tree)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regla=='Sin':\n",
    "    dft=df\n",
    "else:\n",
    "    dft=df\n",
    "    dft[regla]=dft[regla].apply(lambda x: int(x))\n",
    "    dft=dft[dft[regla]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['class_risk']=0\n",
    "dft['class_op_dol_amount']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtr=dft.iloc[:, 0:3] #solución? hay 2 columnas de payment_id..por ahi\n",
    "# dft.rename(columns={'PAY_PAYMENT_ID':'PAY_PAYMENT_ID2'})\n",
    "# dft.rename(index={1:'PAY_PAYMENT_ID'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACERLO CON INDEX ASI SE HACE MAS RAPIDO!\n",
    "\n",
    "# #CREO COLUMNAS PARA DIVIDIR POR PERCENTIL DE VALORES A LOS MONTOS\n",
    "\n",
    "total=dft['op_dol_amount'].sum()\n",
    "dft=dft.sort_values(by='op_dol_amount')\n",
    "dft['op_dol_amount%']=dft['op_dol_amount']/total\n",
    "dft['op_dol_amount%Dist']=0\n",
    "for i in range(int(dft['PAY_PAYMENT_ID'].count())):\n",
    "    if i==0:\n",
    "        dft['op_dol_amount%Dist'].iloc[i]=dft['op_dol_amount%'].iloc[i]\n",
    "    else:\n",
    "        dft['op_dol_amount%Dist'].iloc[i]=dft['op_dol_amount%'].iloc[i]+dft['op_dol_amount%Dist'].iloc[i-1]\n",
    "\n",
    "for r in range(0,percentil):\n",
    "    if r==percentil-1:\n",
    "        Index = dft[(dft['op_dol_amount%Dist']>=r/percentil)].index \n",
    "        dft.loc[Index,'class_op_dol_amount'] = round(dft['op_dol_amount'][(dft['op_dol_amount%Dist']>(0.999))].iloc[0],1)\n",
    "    else:\n",
    "        Index = dft[(dft['op_dol_amount%Dist']>r/percentil)&(dft['op_dol_amount%Dist']<=(r+1)/percentil)].index \n",
    "        dft.loc[Index,'class_op_dol_amount'] = round(dft['op_dol_amount'][(dft['op_dol_amount%Dist']>((r+1)/percentil))&(dft['op_dol_amount%Dist']<=((r+1)/percentil+0.1))].sort_values().iloc[0],1)        \n",
    "        \n",
    "            \n",
    "total=dft['op_dol_amount'].sum()\n",
    "dft=dft.sort_values(by='risk')\n",
    "dft['op_dol_amount%2']=dft['op_dol_amount']/total\n",
    "dft['op_dol_amount%Dist2']=0\n",
    "\n",
    "for i in range(int(dft['PAY_PAYMENT_ID'].count())):\n",
    "    if i==0:\n",
    "        dft['op_dol_amount%Dist2'].iloc[i]=dft['op_dol_amount%2'].iloc[i]\n",
    "    else:\n",
    "        dft['op_dol_amount%Dist2'].iloc[i]=dft['op_dol_amount%2'].iloc[i]+dft['op_dol_amount%Dist2'].iloc[i-1]\n",
    "\n",
    "for j in range(0,percentil):\n",
    "    if j==percentil-1:\n",
    "        Index = dft[(dft['op_dol_amount%Dist2']>=j/percentil)].index \n",
    "        dft.loc[Index,'class_risk'] = round(dft['risk'][(dft['op_dol_amount%Dist2']>(0.999))].iloc[0],4)\n",
    "    else:\n",
    "        Index = dft[(dft['op_dol_amount%Dist2']>j/percentil)&(dft['op_dol_amount%Dist2']<=(j+1)/percentil)].index \n",
    "        dft.loc[Index,'class_risk'] = round((dft['risk'][(dft['op_dol_amount%Dist2']>((j+1)/percentil))&(dft['op_dol_amount%Dist2']<=((j+1)/percentil+0.1))].sort_values()).iloc[0],4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tener el valor máximo, despues ir sumando hasta llegar al valor 10%, del 20% y asi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentro los percentiles del riesgo y del Amount #cantidades\n",
    "# rangeM=[]\n",
    "# rangeR=[]\n",
    "# for i in range (1,round(100/percentil)+1):\n",
    "#     rangeM.append(np.percentile(dft['op_dol_amount'],percentil*i)) #percentile\n",
    "\n",
    "# for j in range (1,round(100/percentil)+1):\n",
    "#     rangeR.append(np.percentile(dft['risk'],percentil*j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo las columnas de los rangos de riesgo y amount\n",
    "\n",
    "\n",
    "# OPCION 1 GRUPOS DE MONTOS\n",
    "# dft['class_op_dol_amount']=0\n",
    "\n",
    "# for r in range(0,round(100/percentil)):\n",
    "#     if r==0:\n",
    "#         Index = dft[(dft['op_dol_amount']<=rangeM[r])].index \n",
    "#         dft.loc[Index,'class_op_dol_amount'] = round(rangeM[r],0)\n",
    "#     elif r==10:\n",
    "#         Index = dft[(dft['op_dol_amount']>rangeM[r-1])].index \n",
    "#         dft.loc[Index,'class_op_dol_amount'] = round(rangeM[r],0)\n",
    "#     else:\n",
    "#         Index = dft[(dft['op_dol_amount']<=rangeM[r])&(dft['op_dol_amount']>rangeM[r-1])].index \n",
    "#         dft.loc[Index,'class_op_dol_amount'] = round(rangeM[r],0)\n",
    "\n",
    "\n",
    "\n",
    "# dft['class_risk']=0\n",
    "\n",
    "# for p in range(0,round(100/percentil)):\n",
    "#     if p==0:\n",
    "#         Index = dft[(dft['risk']<=rangeR[p])].index \n",
    "#         dft.loc[Index,'class_risk'] = round(rangeR[p],4)\n",
    "#     elif p==10:\n",
    "#         Index = dft[(dft['risk']>rangeR[p-1])].index \n",
    "#         dft.loc[Index,'class_risk'] =  round(rangeR[p],4) \n",
    "#     else:\n",
    "#         Index = dft[(dft['risk']<=rangeR[p])&(dft['risk']>rangeR[p-1])].index \n",
    "#         dft.loc[Index,'class_risk'] =  round(rangeR[p],4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo todas las tablas que me interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfw = pd.DataFrame(pivot_)\n",
    "# dfw.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de IncomingPF por Amount\n",
    "pivot_=dft.pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True)#para ver cantidad, cambiar sum por \n",
    "pivot_=pivot_['op_dol_amount']\n",
    "IncomingTot=pivot_.sum().sum()/4\n",
    "\n",
    "#Distribución de IncomingPF por QTY\n",
    "pivot_2=dft.pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "pivot_2=pivot_2['op_dol_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diccMonto={}\n",
    "f=1\n",
    "for i in pivot_.columns:\n",
    "    diccMonto[i]=f\n",
    "    f=f+1\n",
    "diccRisk={}\n",
    "\n",
    "t=1\n",
    "for i in pivot_.index:\n",
    "    diccRisk[i]=t\n",
    "    t=t+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de IncomingPF MIDHIGH  por amount\n",
    "pivot_IMIDHIGH=dft[(dft['STC_PROFILE_ID']=='MIDHIGH')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por                 \n",
    "pivot_IMIDHIGH=pivot_IMIDHIGH['op_dol_amount']\n",
    "\n",
    "#Distribución de TPV por amount\n",
    "pivot_A=dft[(dft['PCC_STATUS']=='A')|(dft['PCC_STATUS']=='D')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "pivot_A=pivot_A['op_dol_amount']\n",
    "Mont_Aprob_corteInicial=pivot_A.sum().sum()/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de TPV LOW por QTY\n",
    "pivot_AQ=dft[((dft['PCC_STATUS']=='A')|(dft['PCC_STATUS']=='D'))&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "pivot_AQ=pivot_AQ['op_dol_amount']\n",
    "\n",
    "#Distribución de TPV LOW  por amount\n",
    "pivot_ALOW=dft[((dft['PCC_STATUS']=='A')|(dft['PCC_STATUS']=='D'))&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por         \n",
    "pivot_ALOW=pivot_ALOW['op_dol_amount']\n",
    "Mont_AprobLOW_corteInicial=pivot_ALOW.sum().sum()/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de TPV MIDHIGH  por amount\n",
    "try:\n",
    "    pivot_AMIDHIGH=dft[((dft['PCC_STATUS']=='A')|(dft['PCC_STATUS']=='D'))&(dft['STC_PROFILE_ID']=='MIDHIGH')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por                 \n",
    "    pivot_AMIDHIGH=pivot_AMIDHIGH['op_dol_amount']\n",
    "except:\n",
    "    pivot_AMIDHIGH=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Niveles de cbk por grupo\n",
    "try:\n",
    "    pivot_cbk=dft[dft['FLAG_NOTIF_CBK']==1].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk=pivot_cbk['op_dol_amount']\n",
    "    DistrCbkusd=(pivot_cbk.sum().sum()/4)\n",
    "    DistrCbkTot=pivot_cbk*100/DistrCbkusd\n",
    "except:\n",
    "    pivot_cbk=0\n",
    "    \n",
    "#Niveles de cbk LOW por grupo\n",
    "try:\n",
    "    pivot_cb82=dft[(dft['FLAG_NOTIF_CBK']==1)&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cb82=pivot_cb82['op_dol_amount']\n",
    "    DistrCbkLOWusd=(pivot_cb82.sum().sum()/4)\n",
    "    DistrCbkLow=pivot_cb82*100/DistrCbkLOWusd\n",
    "\n",
    "except:\n",
    "    pivot_cb82=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QTY cbks\n",
    "try:\n",
    "    pivot_cbk0=dft[dft['FLAG_NOTIF_CBK']==1].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk0=pivot_cbk0['op_dol_amount']\n",
    "except:\n",
    "    pivot_cbk0=0\n",
    "\n",
    "#QTY cbks LOW\n",
    "try:\n",
    "    pivot_cbk01=dft[(dft['FLAG_NOTIF_CBK']==1)&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk01=pivot_cbk01['op_dol_amount']\n",
    "except:\n",
    "    pivot_cbk01=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CUANDO HAY UNA FILA SIN VALORES en classmonto, ACA SE LA AGREGA CON ALGUNOS VALORES NULL... A REVISAR!! \n",
    "# u=0\n",
    "# for x in list(diccMonto.keys())[:-1]:\n",
    "#     r=10\n",
    "#     for i in list(dft['class_op_dol_amount'][(dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1)&(dft['STC_PROFILE_ID']=='LOW')].unique()):\n",
    "#         if x==i:\n",
    "#             r=r-1\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     if r==10: #ACA CAMBIAR EL 10!!\n",
    "#         u=u+1\n",
    "#         dft=dft.append({'class_risk' : dft['class_risk'].unique()[0] ,'STC_PROFILE_ID':'LOW','FLAG_NOTIF_CBK_NO_TRANSACCIONAL':1,'FLAG_NOTIF_CBK':1,'op_dol_amount':0.0002,'class_op_dol_amount':x},ignore_index=True)\n",
    "\n",
    "# # dft[dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1].tail(10)\n",
    "\n",
    "# # CUANDO HAY UNA FILA SIN VALORES, ACA SE LA AGREGA CON ALGUNOS VALORES NULL... A REVISAR!! \n",
    "# for x in list(diccRisk.keys())[:-1]:\n",
    "#     r=10\n",
    "#     for i in list(dft['class_risk'][(dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1)&(dft['STC_PROFILE_ID']=='LOW')].unique()):\n",
    "#         if x==i:\n",
    "#             r=r-1\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     if r==10: #ACA CAMBIAR EL 10!!\n",
    "#         u=u+1\n",
    "#         dft=dft.append({'class_risk' : x ,'STC_PROFILE_ID':'LOW','FLAG_NOTIF_CBK_NO_TRANSACCIONAL':1,'FLAG_NOTIF_CBK':1,'op_dol_amount':0.0002,'class_op_dol_amount':dft['class_op_dol_amount'].unique()[0]},ignore_index=True)\n",
    "\n",
    "# dft[dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1].tail(10)\n",
    "\n",
    "# print('Se creaeron',u,'cbks para que haya 10 filas y 10 columnas')\n",
    "\n",
    "\n",
    "# OPCION 2. EN LA DATAFREMA AGREGAR LA FILA! PERO TENGO LIO PARA ORDENAR CON LA COLUMNA ALL...\n",
    "\n",
    "# df_Aux={1:[0] ,2:[0],3:[0]}\n",
    "# df_Aux = pd.DataFrame(df_Aux)     \n",
    "# df_Aux=df_Aux.reindex([0.104], axis=0)\n",
    "# w=pd.concat([DistrCbkLsT, df_Aux]).fillna(0)\n",
    "# # w=w.drop(['All'], axis=0) # Drop columns Temporaly. DROP (Columnas no tienen index!)\n",
    "# # w.sort_index(axis=0,kind='heapsort')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución de cbk por amount\n",
    "try:\n",
    "    pivot_cbkF=dft[dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbkF=pivot_cbkF['op_dol_amount']\n",
    "except:\n",
    "    pivot_cbkF=0\n",
    "    \n",
    "#QTY cbks transaccional\n",
    "try:\n",
    "    pivot_cbk0F=dft[dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk0F=pivot_cbk0F['op_dol_amount']\n",
    "except:\n",
    "    pivot_cbk0F=0\n",
    "\n",
    "#QTY cbks LOW transaccional\n",
    "try:\n",
    "    pivot_cbk01F=dft[(dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1)&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.size, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk01F=pivot_cbk01F['op_dol_amount']\n",
    "    \n",
    "except:\n",
    "    pivot_cbk01F=0\n",
    "    \n",
    "# cbks LOW y sin ser trnasaccionales en monto\n",
    "try:\n",
    "    pivot_cbk01T=dft[(dft['FLAG_NOTIF_CBK_NO_TRANSACCIONAL']==1)&(dft['STC_PROFILE_ID']=='LOW')].pivot_table(index=['class_risk'],columns=['class_op_dol_amount'],values=['op_dol_amount'],aggfunc=np.sum, fill_value=0,margins=True) #para ver cantidad, cambiar sum por \n",
    "    pivot_cbk01T=pivot_cbk01T['op_dol_amount']\n",
    "    CbkbTotLow_Tran=pivot_cbk01T.sum().sum()/4\n",
    "    DistrCbkLsT=pivot_cbk01T*100/CbkbTotLow_Tran\n",
    "    \n",
    "    \n",
    "except:\n",
    "    DistrCbkLsT=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_cbkprofile=dft[dft['PCC_STATUS']=='A'].pivot_table(index=['FLAG_NOTIF_CBK'],columns=['STC_PROFILE_ID'],values=['op_dol_amount'],aggfunc=np.sum,margins=True) #para ver cantidad, cambiar sum por                 \n",
    "\n",
    "w1=pivot_cbkprofile.iloc[1,0]/(pivot_cbkprofile.iloc[2,0])\n",
    "w3=pivot_cbkprofile.iloc[1,2]/(pivot_cbkprofile.iloc[2,2])\n",
    "try:\n",
    "    w2=pivot_cbkprofile.iloc[1,1]/(pivot_cbkprofile.iloc[2,1])\n",
    "    texto4= 'Cbk total:'+str(round(w3*100,1))+'% donde el LOW es '+str(round(w1*100,1))+'% y el MIDHIGH '+str(round(w2*100,1))+'%'\n",
    "except:\n",
    "    texto4='Cbk total:'+str(round(w3*100,1))+'% donde el LOW es '+str(round(w1*100,1))+'%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Niveles de Cbks LOW con transaccionales por grupo\n",
    "AcbkTL=pivot_cb82.div(pivot_ALOW, level=1)\n",
    "AcbkTL=AcbkTL.apply(lambda x: round((x * 100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Niveles de Cbks LOW sin ser transaccionales por grupo\n",
    "AcbkT=pivot_cbk01T.div(pivot_ALOW, level=1)\n",
    "AcbkT=AcbkT.apply(lambda x: round((x * 100),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribución InocmingPF por Amount en %\n",
    "pivot_12=(pivot_/(dft['op_dol_amount'].sum()))\n",
    "s=pivot_12.apply(lambda x: round((x * 100),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niveles de Aprobación por grupo\n",
    "A=pivot_A.div(pivot_, level=1, fill_value=0)\n",
    "AA=A.apply(lambda x: round((x * 100),0))\n",
    "AA      \n",
    "\n",
    "# Niveles de aprobación LOW por grupo\n",
    "ALOW=pivot_ALOW.div(pivot_, level=1, fill_value=0)\n",
    "AALOW=ALOW.apply(lambda x: round((x * 100),3))\n",
    "AALOW \n",
    "\n",
    "# Niveles de aprobaicón MIDHIGH por grupo\n",
    "try:\n",
    "    AMIDHIGH=pivot_AMIDHIGH.div(pivot_IMIDHIGH, level=1, fill_value=0)\n",
    "    AAMIDHIGH=AMIDHIGH.apply(lambda x: round((x * 100),3))\n",
    "    AAMIDHIGH\n",
    "except:\n",
    "    AAMIDHIGH=0\n",
    "    \n",
    "# Niveles de %cbks por grupo\n",
    "try:\n",
    "    Acbk=pivot_cbk.div(pivot_A, level=1)\n",
    "    Acbk=Acbk.apply(lambda x: round((x * 100),2))\n",
    "    Acbk\n",
    "except:\n",
    "    Acbk=0\n",
    "\n",
    "# # plt.figure(figsize=[16,4]) # create a new figure. CREATE. If note, you will modify last figure\n",
    "# f, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(30,15))\n",
    "# sns.heatmap(AA,annot=True, ax=ax1)\n",
    "# sns.heatmap(AALOW,annot=True, ax=ax2)\n",
    "# try:\n",
    "#     sns.heatmap(AAMIDHIGH,annot=True, ax=ax3)\n",
    "# except:\n",
    "#     print('sin midhigh aprobado')\n",
    "# try:\n",
    "#     sns.heatmap(Acbk,annot=True, ax=ax4)\n",
    "# except:\n",
    "#     print('NO hay cbks en este periodo')\n",
    "\n",
    "# if (dft['PAY_TRY_LAST'].min()==0):\n",
    "#     Rein='con reintentos'\n",
    "# else:\n",
    "#     Rein='sin reintenos'\n",
    "    \n",
    "\n",
    "# print('Comparación de riesgo/aprobación desde',desde,'hasta',hasta,'SOLO en el arbol',tree,Rein,'\\n\\n')\n",
    "# # sns.set(font_scale=2)\n",
    "# print('En cada grupo se ve el valor maximo al que pertenece. \\n')\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistrCbkLsT.size()\n",
    "Aux0=np.zeros((11,11)) #Zeros matrix\n",
    "Aux0=pd.DataFrame(Aux0)\n",
    "Aux0=Aux0.reindex(list(s.index),axis=0)\n",
    "Aux0=Aux0.reindex(list(s.columns),axis=1)\n",
    "Aux0=Aux0.fillna(0)\n",
    "DistrCbkLsT=Aux0+DistrCbkLsT\n",
    "DistrCbkLsT=DistrCbkLsT.fillna(0)\n",
    "\n",
    "AcbkT=Aux0+AcbkT\n",
    "AcbkT=AcbkT.fillna(0)\n",
    "\n",
    "pivot_cbk01T=Aux0+pivot_cbk01T\n",
    "pivot_cbk01T=pivot_cbk01T.fillna(0)\n",
    "\n",
    "AcbkTL=Aux0+AcbkTL\n",
    "AcbkTL=AcbkTL.fillna(0)\n",
    "\n",
    "pivot_A=Aux0+pivot_A\n",
    "pivot_A=pivot_A.fillna(0)\n",
    "\n",
    "DistrCbkLow=DistrCbkLow+Aux0\n",
    "DistrCbkLow=DistrCbkLow.fillna(0)\n",
    "pivot_cb82=Aux0+pivot_cb82\n",
    "pivot_cb82=pivot_cb82.fillna(0)\n",
    "\n",
    "\n",
    "pivot_cbk0=Aux0+pivot_cbk0\n",
    "pivot_cbk0=pivot_cbk0.fillna(0)\n",
    "\n",
    "pivot_cbk01=Aux0+pivot_cbk01\n",
    "pivot_cbk01=pivot_cbk01.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textF)\n",
    "print('IncomingPF del arbol (usd):',str(round(int(IncomingTot),0)),'\\n TPV del arbol (usd):',str(round(int(Mont_AprobLOW_corteInicial),0)),'\\n CBK del arbol (usd):',str(int(round(DistrCbkusd,0))),'\\n CBK LOW del arbol (usd):',str(int(round(DistrCbkLOWusd,0))),'\\n\\n TPN:'\n",
    "      +str(int(pivot_2.sum().sum()/4)),'\\n CBK (qty):',str(int(dfIn1['FLAG_NOTIF_CBK'].sum())),'\\n CBK LOW sin Tran(qty):',\n",
    "      str(int(dfIn1['FLAG_NOTIF_CBK_NO_TRANSACCIONAL'][dfIn1['STC_PROFILE_ID']=='LOW'].sum().sum())),'\\n CKBK transac(qty):',\n",
    "    str(int(dfIn1['FLAG_NOTIF_CBK_NO_TRANSACCIONAL'].sum())),'\\n CBK LOW (qty):',str(int(dfIn1['FLAG_NOTIF_CBK'][dfIn1['STC_PROFILE_ID']=='LOW'].sum().sum())),'\\n')\n",
    "\n",
    "# print(texto3,'Se tomo de base a',Regla_En)\n",
    "print(texto2,'.Se trabajo solo sobre este flujo')\n",
    "\n",
    "# print(texto5)\n",
    "plt.title('Nodos de rechazo en el arbol '+tree)\n",
    "plt.pie(pivot_1['op_dol_amount'],labels=pivot_1.index,autopct='%.2f')\n",
    "plt.show('porcentajes de pagos aprobados, rechazados, etc.')\n",
    "plt.show('Configuración')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax1, ax2,ax3,ax4)) = plt.subplots(4, figsize=(20,20))\n",
    "sns.heatmap(s,annot=True, ax=ax1,vmax=3,robust=True,cmap=\"YlGnBu\")  #Distribución del Incoming PF\n",
    "sns.heatmap(AALOW,annot=True, ax=ax2,robust=True,cmap=\"Blues\")  #Nivel aprobación LOW\n",
    "sns.heatmap(DistrCbkLow,annot=True, ax=ax3,vmax=5,robust=True,cmap=\"YlGnBu\") #Distribución del cbk LOW sin transaccional por grupo. DistrCbkTot(tot)/DistrCbkLow (Low)/DistrCbkLsT (LOW y transacc)\n",
    "sns.heatmap(AcbkTL,annot=True, ax=ax4,cmap=\"Blues\",robust=True) # %AcbkTL=cbks LOW/ AcbkT=cbk LOW sin transaccional \n",
    "ax1.title.set_text('Distribución del Incoming PF')\n",
    "ax2.title.set_text('Nivel de aprobación LOW')\n",
    "ax3.title.set_text('Distribución del cbk LOW (suma es % de Captura)')\n",
    "ax4.title.set_text('Nivel de cbks LOW (promedio es % de Eficiencia)')\n",
    "f. tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(list(s.index)[:-1])\n",
    "print(list(s. columns)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT NUEVO CORTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empieza desde monto 0 y riesgo 0\n",
    "\n",
    "Riesgo_Hasta1= 0.0198\n",
    "Monto_Hasta1= 2226.1 #Lo incluye\n",
    "\n",
    "Riesgo_Hasta2=0\n",
    "Monto_Hasta2=0 #Monto Hasta\n",
    "\n",
    "Riesgo_Hasta3=0 #Sino poner 0\n",
    "Monto_Hasta3=0 #Sino poner 0\n",
    "\n",
    "Riesgo_Hasta4=0 #Sino poner 0\n",
    "Monto_Hasta4=0  #Sino poner 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULO DE TPV APROBADO NUEVO CORTE (Mismo tpv con mas restricciones)\n",
    "\n",
    "g1=pivot_A.iloc[0:diccRisk[Riesgo_Hasta1],0:diccMonto[Monto_Hasta1]] #filas & columnas\n",
    "Sg1=g1.sum().sum()\n",
    "AprobCorte=Sg1\n",
    "\n",
    "try:\n",
    "    g2=pivot_A.iloc[0:diccRisk[Riesgo_Hasta2],diccMonto[Monto_Hasta1]:diccMonto[Monto_Hasta2]] #filas & columnas\n",
    "    Sg2=g2.sum().sum()\n",
    "    AprobCorte=AprobCorte+Sg2\n",
    "except:\n",
    "    print('Sin bloque 2')\n",
    "\n",
    "try:\n",
    "    g3=pivot_A.iloc[0:diccRisk[Riesgo_Hasta3],diccMonto[Monto_Hasta2]:diccMonto[Monto_Hasta3]] #filas & columnas\n",
    "    Sg3=g3.sum().sum()\n",
    "    AprobCorte=AprobCorte+Sg3\n",
    "except:\n",
    "    print('Sin bloque 3')\n",
    "try:\n",
    "    g4=pivot_A.iloc[0:diccRisk[Riesgo_Hasta4],diccMonto[Monto_Hasta3]:diccMonto[Monto_Hasta4]] #filas & columnas\n",
    "    Sg4=g4.sum().sum()\n",
    "    AprobCorte=AprobCorte+Sg4\n",
    "except:\n",
    "    print('Sin bloque 4')\n",
    "    \n",
    "AprobCortePorc=AprobCorte/IncomingTot\n",
    "AprobCorteTeo=Mont_AprobLOW_corteInicial/IncomingTot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULO DE CBK APROBADO CON  NUEVO CORTE\n",
    "\n",
    "h1=pivot_cb82.iloc[0:diccRisk[Riesgo_Hasta1],0:diccMonto[Monto_Hasta1]] #filas & columnas\n",
    "Sh1=h1.sum().sum()\n",
    "CbkbCorte=Sh1\n",
    "\n",
    "try:\n",
    "    h2=pivot_cb82.iloc[0:diccRisk[Riesgo_Hasta2],diccMonto[Monto_Hasta1]:diccMonto[Monto_Hasta2]] #filas & columnas\n",
    "    Sh2=h2.sum().sum()\n",
    "    CbkbCorte=CbkbCorte+Sh2\n",
    "except:\n",
    "    print('Sin bloque 2')\n",
    "\n",
    "try:\n",
    "    h3=pivot_cb82.iloc[0:diccRisk[Riesgo_Hasta3],diccMonto[Monto_Hasta2]:diccMonto[Monto_Hasta3]] #filas & columnas\n",
    "    Sh3=h3.sum().sum()\n",
    "    CbkbCorte=CbkbCorte+Sh3\n",
    "except:\n",
    "    print('Sin bloque 3')\n",
    "try:\n",
    "    h4=pivot_cb82.iloc[0:diccRisk[Riesgo_Hasta4],diccMonto[Monto_Hasta3]:diccMonto[Monto_Hasta4]] #filas & columnas\n",
    "    Sh4=h4.sum().sum()\n",
    "    CbkbCorte=CbkbCorte+Sh4\n",
    "except:\n",
    "    print('Sin bloque 4')\n",
    "    \n",
    "CbkCortePorc=CbkbCorte/Mont_AprobLOW_corteInicial\n",
    "CbkInicial=DistrCbkLOWusd/Mont_AprobLOW_corteInicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTADO NUEVO CORTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( textF,'\\n')\n",
    "print('Nivel de aprobación LOW  del arbol',tree,':',round(AprobCorteTeo*100,1),'pp')\n",
    "print('Nivel de aprobación LOW del arbol',tree,'con nuevo corte:',round(AprobCortePorc*100,1),'pp')\n",
    "VarAprobPF=AprobCortePorc-AprobCorteTeo\n",
    "print('Variación de aprobación LOW con nuevo corte:',round((VarAprobPF)*100,2),'pp(',round((AprobCortePorc/AprobCorteTeo-1)*100,1),'%). Si simulo pagos LOW del arbol, se espera nivlel de aprob de',100+round((AprobCortePorc/AprobCorteTeo-1)*100,1),'pp o menos si es que en otros nodos luego lo rechazan\\n. La caida es la comentada. el nivel de aprobación que va a quedar es la comentada+ rechazo strong rules\\n')\n",
    "\n",
    "print('Nivel de CBK LOW real sobre TPV:',round(CbkInicial*100,1),'pp')\n",
    "print('Nivel de Cbk LOW sobre TPV en nuevo corte:',round(CbkCortePorc*100,1),'pp')\n",
    "print('Variación de Cbk LOW sore TPV en nuevo corte:',round((CbkCortePorc-CbkInicial)*100,2),'pp (',round((CbkCortePorc/CbkInicial-1)*100,1),'%)\\n')\n",
    "\n",
    "CbksIncg=DistrCbkLOWusd/IncomingTot\n",
    "Nuevo_CbksIncg=CbkbCorte/IncomingTot\n",
    "Var_CbksIncg=Nuevo_CbksIncg-CbksIncg\n",
    "# print('Nivel de CBK LOW real sobre IncomingPF:',round(CbksIncg*100,1),'pp')\n",
    "# print('Nivel de CBK LOW real sobre IncomingPF nuevo corte:',round(Nuevo_CbksIncg*100,1),'pp ')\n",
    "# print('Variación de CBK LOW real sobre IncomingPF nuevo corte:',round((Var_CbksIncg)*100,2),'pp \\n')\n",
    "\n",
    "# print('EFICIENCIA (con cbk estimado):',round(/(Mont_Aprob_corteInicial-AprobCorte)*100,1),'% (Sobre el TPV LOW rechazado x nuevo corte)') #Del Incoming rechazado, que % es Cbk (falso positivo lo que falta para llegar a 100%)\n",
    "print('EFICIENCIA (con cbk real. estimado es mayor):',round((DistrCbkLOWusd-CbkbCorte)/(Mont_Aprob_corteInicial-AprobCorte)*100,1),'% (Sobre el TPV LOW rechazado x nuevo corte)') #Del Incoming rechazado, que % es Cbk (falso positivo lo que falta para llegar a 100%)\n",
    "print('CAPTURA DEL CBK:',round((DistrCbkLOWusd-CbkbCorte)/DistrCbkLOWusd*100,1),'% (Del total del cbk LOW, cuanto se captura con la nueva regla)')\n",
    "print('RIFP:',round((VarAprobPF-Var_CbksIncg)/Var_CbksIncg,2),'pp (Cuanto aumenta el rechazo HR del Falso Positivo por capturar 1pp de cbk)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Idealmente combinar este nuevo corte con el viejo')\n",
    "print('{\\nIF([#OP_DOL_AMOUNT >=',Monto_Hasta1,'] AND [#RISK >',Riesgo_Hasta1,']){@VERDADERO;}\\nIF([#OP_DOL_AMOUNT >',Monto_Hasta1,'] AND [#OP_DOL_AMOUNT <=',Monto_Hasta2,'] AND [#RISK >',Riesgo_Hasta2,']){@VERDADERO;}\\nIF([#OP_DOL_AMOUNT >',Monto_Hasta2,'] AND [#RISK >',Riesgo_Hasta3,']){@VERDADERO;}\\n@FALSO;}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTRAS METRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER % DE CBKS REAL Y CBK LOW SIN SER TRANSACCIONAL\n",
    "f, (ax1,ax2,ax3) = plt.subplots(3, figsize=(20,20))\n",
    "sns.heatmap(DistrCbkTot,annot=True, ax=ax1,cmap=\"Blues\",robust=True) # Distribución cbk total(LOW + MIDHIGH y con trsansaccionales)\n",
    "sns.heatmap(Acbk,annot=True, ax=ax2,cmap=\"Blues\",robust=True) # % cbk por celda \n",
    "sns.heatmap(AcbkT,annot=True, ax=ax3,cmap=\"Blues\",robust=True) # % cbk Sin transaccional y sin Midhigh por celda\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER POR CANTIDADES\n",
    "f, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(30,15))\n",
    "sns.heatmap(pivot_2,annot=True, ax=ax1,cmap=\"PiYG\") #QTY incoming PF\n",
    "sns.heatmap(pivot_AQ,annot=True, ax=ax2,cmap=\"Blues\") # Qty aprobado LOW\n",
    "sns.heatmap(pivot_cbk0 ,annot=True, ax=ax3) #Qty cbks\n",
    "sns.heatmap(pivot_cbk01,annot=True, ax=ax4) # qty cbk LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #EXPORTAR\n",
    "\n",
    "# import os\n",
    "# from pandas import ExcelWriter\n",
    "# from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "# #Creo archivo\n",
    "# ruta = \"C:/Users/mgaona/Desktop/Analisis/base python/MatrizRiesgo\"+Seller+desde+hasta+\".xlsx\" \n",
    "\n",
    "# #Ingreso las bases a hojas al archivo\n",
    "# df01.to_excel(ruta, index=False)\n",
    "\n",
    "# # Cuando exporte, agregar la query en el excel!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
